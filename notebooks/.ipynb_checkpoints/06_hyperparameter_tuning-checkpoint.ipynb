{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d342168b",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2361bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score, roc_auc_score, f1_score,\\\n",
    "precision_score, roc_auc_score, classification_report, fbeta_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13726419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>target</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>cp_4</th>\n",
       "      <th>restecg_1</th>\n",
       "      <th>restecg_2</th>\n",
       "      <th>thal_6</th>\n",
       "      <th>thal_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  trestbps   chol  fbs  thalach  exang  oldpeak  slope   ca  \\\n",
       "0  63.0  1.0     145.0  233.0  1.0    150.0    0.0      2.3    3.0  0.0   \n",
       "1  67.0  1.0     160.0  286.0  0.0    108.0    1.0      1.5    2.0  3.0   \n",
       "\n",
       "   target  cp_2  cp_3  cp_4  restecg_1  restecg_2  thal_6  thal_7  \n",
       "0       0     0     0     0          0          1       1       0  \n",
       "1       1     0     0     1          0          1       0       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/heart_disease.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "NUMERIC_COLS = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "CATEGORICAL_COLS = [f for f in df.columns if f not in NUMERIC_COLS]\n",
    "\n",
    "# SELECTED_FEATS = ['thal_7', 'thalach', 'ca', 'cp_4', 'oldpeak', 'exang']\n",
    "\n",
    "# NUMERIC_COLS = list(set(NUMERIC_COLS) & set(SELECTED_FEATS))\n",
    "# CATEGORICAL_COLS = list(set(CATEGORICAL_COLS) & set(SELECTED_FEATS))\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd91000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed594b0",
   "metadata": {},
   "source": [
    "# Models Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e2225",
   "metadata": {},
   "source": [
    "- Best three models that showed **high accuracy**:\n",
    "    - Random forest\n",
    "    - Support vector machine\n",
    "    - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a6bcbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLS.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40f08a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor that scales only numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), NUMERIC_COLS),\n",
    "        ('cat', 'passthrough', CATEGORICAL_COLS)\n",
    "    ]\n",
    ")\n",
    "metrics = {} # metrics for each model\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "scoring = f2_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469becc",
   "metadata": {},
   "source": [
    "- The **F2-score** optimally balances the clinical reality that false negatives (missed heart disease) are **more costly** than false positives in most healthcare scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f39274",
   "metadata": {},
   "source": [
    "# Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d287b",
   "metadata": {},
   "source": [
    "### 1. Random forest Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5c0e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CV score: 0.7782\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor), # since binary trees doesn't need scaling\n",
    "    ('cls', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Baseline random forset score\n",
    "print(f\"Baseline CV score: {cross_val_score(rf_pipeline, X_train, y_train, cv=5, scoring=scoring).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4377f",
   "metadata": {},
   "source": [
    "### 2. Random forest grid search (phase 1):\n",
    "- Using **RandomizedSearchCV** with variety of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a06a3657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 1: RANDOM FOREST RANDOM_GRIDSEARCH ===\n",
      "Best random forest params (Phase 1):\n",
      "  cls__bootstrap: False\n",
      "  cls__max_depth: 8\n",
      "  cls__max_features: log2\n",
      "  cls__min_samples_leaf: 5\n",
      "  cls__min_samples_split: 2\n",
      "  cls__n_estimators: 253\n",
      "Best CV score:0.787\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Random Forest Parameter Grid\n",
    "print(\"=== PHASE 1: RANDOM FOREST RANDOM_GRIDSEARCH ===\")\n",
    "rf_param_dist = {\n",
    "    'cls__n_estimators': randint(50, 300), # minimum number of samples at a leaf node\n",
    "    'cls__max_depth': randint(3, 15), # maximum depth of each tree.\n",
    "    'cls__min_samples_split': randint(2, 20), # minimum number of samples to split a node.\n",
    "    'cls__min_samples_leaf': randint(1, 10), # minimum number of samples at a leaf node.\n",
    "    'cls__max_features': ['sqrt', 'log2', 0.5, 0.7], # number of features considered at each split.\n",
    "    'cls__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf_pipeline, rf_param_dist, n_iter=50, cv=5, \n",
    "    scoring=scoring, n_jobs=-1, random_state=42\n",
    ")\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best random forest params (Phase 1):\")\n",
    "for key, value in rf_random_search.best_params_.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Best CV score:{rf_random_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a961d5",
   "metadata": {},
   "source": [
    "### 3. Random forest grid search (phase 2):\n",
    "- Using **GridSearchCV** with more specific parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfe1dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 2: RANDOM FOREST GRIDSEARCH ===\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Random Forest Parameters:\n",
      "  cls__bootstrap: False\n",
      "  cls__max_depth: 10\n",
      "  cls__max_features: log2\n",
      "  cls__min_samples_leaf: 5\n",
      "  cls__min_samples_split: 2\n",
      "  cls__n_estimators: 200\n",
      "Best CV Score: 0.793\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PHASE 2: RANDOM FOREST GRIDSEARCH ===\")\n",
    "\n",
    "best = rf_random_search.best_params_\n",
    "\n",
    "rf_param_grid = {\n",
    "    'cls__n_estimators': [200, 250, 300],      # Slightly increase trees\n",
    "    'cls__max_depth': [max(3, best['cls__max_depth']-2), best['cls__max_depth'], min(20, best['cls__max_depth']+2)],\n",
    "    'cls__min_samples_split': [max(2, best['cls__min_samples_split']-2), best['cls__min_samples_split'], best['cls__min_samples_split']+2],\n",
    "    'cls__min_samples_leaf': [max(1, best['cls__min_samples_leaf']-1), best['cls__min_samples_leaf'], best['cls__min_samples_leaf']+1],\n",
    "    'cls__max_features': [best['cls__max_features']],\n",
    "    'cls__bootstrap': [best['cls__bootstrap']]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\")\n",
    "for key, value in rf_grid_search.best_params_.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Best CV Score: {rf_grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563bebca",
   "metadata": {},
   "source": [
    "### 4. Evaluation for random forest best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ef9faa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST SET PERFORMANCE ===\n",
      "CV_Score: 0.793\n",
      "Test_Accuracy: 0.918\n",
      "Test_Precision: 0.897\n",
      "Test_Recall: 0.929\n",
      "Test_F1: 0.912\n",
      "Test_AUC: 0.953\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics['Random Forest'] = {\n",
    "    'Best_Params': rf_grid_search.best_params_,\n",
    "    'CV_Score': rf_grid_search.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_rf),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_rf),\n",
    "    'Test_F1': f1_score(y_test, y_pred_rf),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_pred_proba_rf)\n",
    "}\n",
    "\n",
    "print(\"\\n=== TEST SET PERFORMANCE ===\")\n",
    "for metric, value in list(metrics['Random Forest'].items())[1:]:  # Skip first items\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd54aa",
   "metadata": {},
   "source": [
    "# Support vector machine hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb5193",
   "metadata": {},
   "source": [
    "### 1. Support vector machine Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0db0c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CV score: 0.7278\n"
     ]
    }
   ],
   "source": [
    "# SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('cls', SVC(probability=True, random_state=42))  # probability=True for AUC\n",
    "])\n",
    "\n",
    "# Baseline support vector score\n",
    "print(f\"Baseline CV score: {cross_val_score(svm_pipeline, X_train, y_train, cv=5, scoring=scoring).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd397b",
   "metadata": {},
   "source": [
    "### 2. SVM grid search (phase 1):\n",
    "- Using **RandomizedSearchCV** with variety of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d8eb39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 1: SUPPORT VECTOR MACHINE RANDOM_GRIDSEARCH ===\n",
      "Best params (Phase 1):\n",
      "  cls__kernel: linear\n",
      "  cls__gamma: 0.0069519279617756054\n",
      "  cls__class_weight: None\n",
      "  cls__C: 26.366508987303554\n",
      "Best CV score :0.803\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Support Vector Machine Parameter Grid\n",
    "print(\"=== PHASE 1: SUPPORT VECTOR MACHINE RANDOM_GRIDSEARCH ===\")\n",
    "\n",
    "# linear and rbf kernel\n",
    "svm_param_dist = {\n",
    "    \"cls__C\": np.logspace(-3, 3, 20),        # 0.001 → 1000\n",
    "    \"cls__gamma\": np.logspace(-4, 1, 20),    # 0.0001 → 10\n",
    "    \"cls__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"cls__class_weight\": [None, \"balanced\"]\n",
    "    \n",
    "}\n",
    "\n",
    "# poly kernel\n",
    "# svm_param_dist = {\n",
    "#     \"cls__kernel\": [\"poly\"],\n",
    "#     \"cls__degree\": [2, 3],\n",
    "#     \"cls__C\": [0.1, 1, 10],\n",
    "#     \"cls__gamma\": [\"scale\", \"auto\", 0.01, 0.1],\n",
    "#     \"cls__coef0\": [0, 1]\n",
    "# }\n",
    "\n",
    "svm_random_search = RandomizedSearchCV(\n",
    "    svm_pipeline, svm_param_dist, n_iter=50, cv=5, \n",
    "    scoring=scoring, n_jobs=-1, random_state=42\n",
    ")\n",
    "svm_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params (Phase 1):\")\n",
    "for key, value in svm_random_search.best_params_.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Best CV score :{svm_random_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9caa0",
   "metadata": {},
   "source": [
    "### 3. SVM grid search (phase 2):\n",
    "- Using **GridSearchCV** with more specific parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99cf194b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 2: SUPPORT VECTOR MACHINE GRIDSEARCH ===\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best model parameters:\n",
      "  cls__C: 26.366508987303554\n",
      "  cls__class_weight: None\n",
      "  cls__kernel: linear\n",
      "Best CV Score: 0.803\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PHASE 2: SUPPORT VECTOR MACHINE GRIDSEARCH ===\")\n",
    "\n",
    "best = svm_random_search.best_params_\n",
    "\n",
    "# for linear kernel\n",
    "svm_param_grid = {\n",
    "    \"cls__C\": [800, best['cls__C'], 1500],\n",
    "    \"cls__kernel\": [best['cls__kernel']],\n",
    "    \"cls__class_weight\": [best['cls__class_weight']]\n",
    "}\n",
    "\n",
    "svm_grid_search = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    svm_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best model parameters:\")\n",
    "for key, value in svm_grid_search.best_params_.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Best CV Score: {svm_grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e16a6",
   "metadata": {},
   "source": [
    "### 4. Evaluation for Support Vector Machine best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce7b3c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST SET PERFORMANCE ===\n",
      "CV_Score: 0.803\n",
      "Test_Accuracy: 0.869\n",
      "Test_Precision: 0.812\n",
      "Test_Recall: 0.929\n",
      "Test_F1: 0.867\n",
      "Test_AUC: 0.950\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model\n",
    "best_svm = svm_grid_search.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "y_pred_proba_svm = best_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics['SVM'] = {\n",
    "    'Best_Params': svm_grid_search.best_params_,\n",
    "    'CV_Score': svm_grid_search.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_svm),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_svm),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_svm),\n",
    "    'Test_F1': f1_score(y_test, y_pred_svm),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_pred_proba_svm)\n",
    "}\n",
    "\n",
    "print(\"\\n=== TEST SET PERFORMANCE ===\")\n",
    "for metric, value in list(metrics['SVM'].items())[1:]:\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1225124",
   "metadata": {},
   "source": [
    "## Logistic regression hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b7667",
   "metadata": {},
   "source": [
    "### 1. Logistic regression Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9874133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CV score: 0.7882\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('cls', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Baseline Logistic Regression\n",
    "print(f\"Baseline CV score: {cross_val_score(lr_pipeline, X_train, y_train, cv=5, scoring=scoring).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825a2a5",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression grid search (phase 1):\n",
    "- Using **RandomizedSearchCV** with variety of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6c2956a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 1: LOGISTIC REGRESSION RANDOM_GRIDSEARCH ===\n",
      "Best params (Phase 1):\n",
      "  cls__solver: liblinear\n",
      "  cls__penalty: l2\n",
      "  cls__l1_ratio: 0.5\n",
      "  cls__class_weight: balanced\n",
      "  cls__C: 0.001\n",
      "Best CV score :0.846\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Logistic Regression Parameter Grid\n",
    "print(\"=== PHASE 1: LOGISTIC REGRESSION RANDOM_GRIDSEARCH ===\")\n",
    "\n",
    "lr_param_dist = {\n",
    "    \"cls__penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"cls__C\": np.logspace(-3, 3, 50),    # 0.001 → 1000\n",
    "    \"cls__solver\": [\"liblinear\", \"saga\"],  # supports l1 & elasticnet\n",
    "    \"cls__class_weight\": [None, \"balanced\"],\n",
    "    \"cls__l1_ratio\": np.linspace(0, 1, 5)  # only matters if elasticnet\n",
    "}\n",
    "\n",
    "lr_random_search = RandomizedSearchCV(\n",
    "    lr_pipeline, lr_param_dist, n_iter=50, cv=5, \n",
    "    scoring=scoring, n_jobs=-1, random_state=42\n",
    ")\n",
    "lr_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params (Phase 1):\")\n",
    "for key, value in lr_random_search.best_params_.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Best CV score :{lr_random_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034391d",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression grid search (phase 2):\n",
    "- Using **GridSearchCV** with more specific parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4230a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 2: LOGISTIC REGRESSION GRIDSEARCH ===\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best model parameters:\n",
      "  cls__C: 0.0001\n",
      "  cls__class_weight: balanced\n",
      "  cls__penalty: l2\n",
      "  cls__solver: liblinear\n",
      "Best CV Score: 0.853\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PHASE 2: LOGISTIC REGRESSION GRIDSEARCH ===\")\n",
    "\n",
    "best = lr_random_search.best_params_\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"cls__C\": np.logspace(-4, -1, 10),   # narrower range\n",
    "    \"cls__penalty\": [best[\"cls__penalty\"]],\n",
    "    \"cls__solver\": [best[\"cls__solver\"]],\n",
    "    \"cls__class_weight\": [best[\"cls__class_weight\"]]\n",
    "}\n",
    "\n",
    "lr_grid_search = GridSearchCV(\n",
    "    lr_pipeline,\n",
    "    lr_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best model parameters:\")\n",
    "for key, value in lr_grid_search.best_params_.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"Best CV Score: {lr_grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ccb025",
   "metadata": {},
   "source": [
    "### 4. Evaluation for Logistic Regression best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a623b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST SET PERFORMANCE ===\n",
      "CV_Score: 0.853\n",
      "Test_Accuracy: 0.672\n",
      "Test_Precision: 0.583\n",
      "Test_Recall: 1.000\n",
      "Test_F1: 0.737\n",
      "Test_AUC: 0.951\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model\n",
    "best_lr = lr_grid_search.best_estimator_\n",
    "y_pred_lr = best_lr.predict(X_test)\n",
    "y_pred_proba_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics['Logistic Regression'] = {\n",
    "    'Best_Params': lr_grid_search.best_params_,\n",
    "    'CV_Score': lr_grid_search.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_lr),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_lr),\n",
    "    'Test_F1': f1_score(y_test, y_pred_lr),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_pred_proba_lr)\n",
    "}\n",
    "\n",
    "print(\"\\n=== TEST SET PERFORMANCE ===\")\n",
    "for metric, value in list(metrics['Logistic Regression'].items())[1:]:\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636bd99",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6d90e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "================================================================================\n",
      "                 Model  CV_Score  Test_Accuracy  Test_Precision  Test_Recall  \\\n",
      "0  Logistic Regression  0.853067       0.672131        0.583333     1.000000   \n",
      "1        Random Forest  0.793257       0.918033        0.896552     0.928571   \n",
      "2                  SVM  0.802667       0.868852        0.812500     0.928571   \n",
      "\n",
      "    Test_F1  Test_AUC  \n",
      "0  0.736842  0.951299  \n",
      "1  0.912281  0.953463  \n",
      "2  0.866667  0.950216  \n",
      "\n",
      "================================================================================\n",
      "BEST PARAMETERS FOR EACH MODEL\n",
      "================================================================================\n",
      "\n",
      "Logistic Regression:\n",
      "  cls__C: 0.0001\n",
      "  cls__class_weight: balanced\n",
      "  cls__penalty: l2\n",
      "  cls__solver: liblinear\n",
      "\n",
      "Random Forest:\n",
      "  cls__bootstrap: False\n",
      "  cls__max_depth: 10\n",
      "  cls__max_features: log2\n",
      "  cls__min_samples_leaf: 5\n",
      "  cls__min_samples_split: 2\n",
      "  cls__n_estimators: 200\n",
      "\n",
      "SVM:\n",
      "  cls__C: 26.366508987303554\n",
      "  cls__class_weight: None\n",
      "  cls__kernel: linear\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": best_lr,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"SVM\": best_svm,\n",
    "}\n",
    "all_grids = {\n",
    "        'Random Forest': rf_grid_search,\n",
    "        'SVM': svm_grid_search,\n",
    "        'Logistic Regression': lr_grid_search\n",
    "}\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        **metrics[name],\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(df_results.drop(columns='Best_Params'))\n",
    "\n",
    "# Display best parameters for each model\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BEST PARAMETERS FOR EACH MODEL\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for i in results:\n",
    "        print(f\"\\n{i['Model']}:\")\n",
    "        for param, value in i['Best_Params'].items():\n",
    "            print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd2e5a",
   "metadata": {},
   "source": [
    "Since `Random Forest` was the most accurate in terms of precision-recall balance, we deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e7cbe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/final_model.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(models['Random Forest'], \"../models/final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01f12f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
